# ДИПЛОМНЫЙ ПРОЕКТ (HW-04) - с пояснениями исполнителя

**Примечание:** так выделяются

> *Пояснения от исполнителя*

**Примечание:** сопровождающие задание заказчика рисунки, формулировки оставлены исполнителем без изменений.

## Введение

![Motivation](https://lms.skillfactory.ru/assets/courseware/v1/90c0116254de8cad509ea1d79de7e61b/asset-v1:SkillFactory+DEVOPS-3.0+2021+type@asset+block/%D0%92%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5_1.1.png)

Всем привет!

Ну что, можно вас поздравить с прохождением основного материала по курсу. Теперь вас можно назвать специалистом начального уровня! Конечно, не хватает какой-то последней детальки пазла, и эта деталь — финальный дипломный проект.

Да, это финишная прямая. Сейчас самый сложный рывок — придется напрячь серое вещество в голове. Будет сложно, но это важно.

### Что будем делать?

Будем настраивать полный цикл CI/CD внутри компании.

Представим, что нас позвали на работу, как единственного DevOps-специалиста в маленькую компанию, где есть пара проектов. Люди работают просто в Git, и у них нет никаких окружений.

> *Единственный специалист => разделение на множество репозиториев в общем случае вредно (до понимания специфики уже в процессе эксплуатации). Иными словами: "преждевременная оптимизация - зло".*

Наша задача — автоматизировать их рутину и облегчить всем остальным жизнь.

### Зачем это нужно?

Зачем это всё — вопрос закономерный. Ведь теперь вы знаете, какие инструменты DevOps-инженера есть в его рукаве. Может даже запомнили, когда, где и что нужно применять. Но, чтобы понять картину целиком, нам нужно всё это связать воедино. От и до прочувствовать весь процесс настройки инфраструктуры и процессов внутри.

Вдобавок ко всему после реализации этого проекта вы сможете быть уверены в себе на собеседовании, ведь вы это делали не только по лекалам онлайн-курса. В этот раз весь код конфигураций будет лежать на вас. Мы лишь только опишем итоговый результат, который должен получиться.

### Структура проекта

В процессе выполнения проекта необходимо будет описать в Git:

- конфигурации серверов в облачной инфраструктуре (IaC);
- пайплайны для сборки и деплоя исходного приложения.
- конфигурации мониторинга и сборку логов этого приложения.

Всего три пункта. Общими словами, конечно, выглядит легко. Но это только на первый взгляд. Всего будет три недели на выполнения проекта, поэтому придется постараться.

Итак, начнем, впереди первый спринт!


## Спринт 1

![Motivation](https://lms.skillfactory.ru/assets/courseware/v1/26d8172e2f203e0049b45ad9c711daae/asset-v1:SkillFactory+DEVOPS-3.0+2021+type@asset+block/Sprint_1.1.png)

Давайте засучим рукава и начнем реализовывать наш амбициозный проект!

По идее, в отдельности вы всё это уже делали. Осталось только достать эти знания из закромов памяти.


### ЗАДАЧА

Опишите инфраструктуру будущего проекта в виде кода с инструкциями по развертке, нужен кластер Kubernetes и служебный сервер (будем называть его srv).


#### 1 Выбираем облачный провайдер и инфраструктуру.

Нам нужно три сервера:

- два сервера в одном кластере **Kubernetes**: **1 master** и **1 app**;

> *Согласно требованию - ожидается изумительная устойчивость проекта при эксплуатации (1 мастер). При этом требуется использовать в обязательном порядке аналоги baremetal-развертывания без использования managed-продуктов (в случае Яндекс-облака), но с набором несовместимостей (например, использование metalb на уровне l2 - не получится из-за неполной совместимости "сети" яндекса и "настоящей" сети; использование "с bgp" - не получится, потому что bgp нужно будет куда-то терминировать перед "выпуском" наружу, и нарушится требование к серверам (ограниченное количество, роли) и/или "здорОвости" решения (в случае, если endpoint-ом прикладного разворачиваемого приложения testapp пытаться сделать srv-сервер); или, например, невозможность использования полноценных внешних по отношению к кластеру решений хранения данных (внешних СХД/платформ хранения) при почти полной невозможности (ограниченность ресурсов) развернуть внутреннее в режиме устойчивости (в итоге был применен piraeus (на базе linstor/nbd))).*

- сервер **srv** для инструментов мониторинга, логгирования и сборок контейнеров.

#### 2 Описываем инфраструктуру.

Описывать инфраструктуру мы будем, конечно, в **Terraform**.

> Совет: лучше создать под наши конфигурации отдельную группу проектов в Git, например, devops.

> *"Группа проектов" - это частное понятие gitlab; в общем случае совет - не применим (и несколько репозиториев автоматически группой проектов называться не могут).*

Пишем в README.md инструкцию по развертке конфигураций в облаке. Никаких секретов в коде быть не должно.

> *Требование согласно формулировке применяется только к описанию развертывания конфигурации. При этом использование напрямую вшитого в код (развертываемого) приложения SECRET_KEY к задаче развертывания - согласно формулировке - не относится и исправлению - не подлежит.*

#### 3 Автоматизируем установку.

Надо реализовать возможность установки на сервер всех необходимых нам настроек и пакетов, будь то docker-compose, gitlab-runner или наши публичные ключи для доступа по SSH. Положите код автоматизации в Git-репозиторий.

> *Исходя из формулировки ниже "Нужно сделать так, чтобы наше приложение разворачивалось после сборки в Kubernetes" и формулировки выше "сервер srv для инструментов мониторинга, логгирования и сборок контейнеров.", на сервере srv можно использовать **только** kubernetes, и никаких docker-compose (и docker в общем случае) на сервере srv быть **не** должно. (Иначе фраза формулировки должна была бы звучать приблизительно следующим образом: "...приложение после сборки разворачивалось в Kubernetes".)*

> Результат должен быть такой, чтобы после запуска подобной автоматизации на сервере устанавливалось почти всё, что нужно.

Совсем полностью исключать ручные действия не надо, но в таком случае их надо описать в том же **README.md** и положить в репозиторий.

> Совет: лучше использовать для этого **Ansible**.

> *Именно исходя из данной формулировки в решении для деплой terraform-инфрастуктуры, работа с k8s, шаблонизирование файлов в пайплайне производится с помощью Ansible - таково пожелание заказчика (исполнитель о повсеместном уходе от практики использования ansible - осведомлен).*

Этими действиями мы заложим фундамент для дальнейших спринтов.

Если всё получилось, то это невероятно круто! В следующем спринте мы настроим сборку и деплой приложения в созданный кластер. Это, наверное, будет самый ответственный спринт.

> *Исполнитель полностью осознает некорректность предлагаемого здесь подхода - реализацию логгирования и мониторинга только после развертывания (при этом варианты решения проблем развертывания без логов и мониторинга заказчиком не предлагаются) - и не в ущерб общей задаче в предлагаемой исполнителем реализации мониторинг, логгирование (а также доступ к собираемой информации) как для обслуживающего кластера k8s (srv), так и для кластера k8s предметной области (dev) - фактически полностью реализуются не спринтом 3, а спринтом 1.*

###   Модули к спринту

- [Управление инфраструктурой](https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DEVOPS-3.0+2021/courseware/1818f1e4a2fa4e2aace76827bb5ed460/d2da211a72114c6281dc171ca2421366/1?activate_block_id=block-v1%3ASkillFactory%2BDEVOPS-3.0%2B2021%2Btype%40vertical%2Bblock%40833b13a592f540ccb885f9db1dc0c272)
- [Работа с облачными инфраструктурами](https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DEVOPS-3.0+2021/courseware/1818f1e4a2fa4e2aace76827bb5ed460/976d1596f76b47839b935b22cbbd2cb9/1?activate_block_id=block-v1%3ASkillFactory%2BDEVOPS-3.0%2B2021%2Btype%40vertical%2Bblock%408ac1cc51122c4b0fa4369091d79bfcb7)
- [Управление конфигурациями](https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DEVOPS-3.0+2021/jump_to/block-v1:SkillFactory+DEVOPS-3.0+2021+type@vertical+block@2a6933b2b0d34fcdb3bf46827a9ae1a9)


## Спринт 2

![Motivation](https://lms.skillfactory.ru/assets/courseware/v1/6f13a6f249d4f29c9bfff3e6e205c1d6/asset-v1:SkillFactory+DEVOPS-3.0+2021+type@asset+block/Sprint_2.1.png)

В прошлом спринте мы с вами описали и создали нашу будущую инфраструктуру.

Теперь давайте её используем — соберем и задеплоим приложение из нашего Git в созданный кластер Kubernetes. Разделим всё на шаги.

#### 1 Клонируем репозиторий, собираем его на сервере srv.

Исходники простого приложения [можно взять здесь](https://github.com/vinhlee95/django-pg-docker-tutorial). Это простое приложение на **Django** с уже написанным Dockerfile. Приложение работает с **PostgreSQL**, в самом репозитории уже есть реализация **docker-compose** — её можно брать за референс при написании **Helm**-чарта.

> *Таким образом, написание helm-чарта для развертывания СУБД/БД для приложения - по существу не требуется, и для данного развертывания можно (и желательно с точки зрения сопровождения) применять чарт от стороннего разработчика (например, bitnami).*

Необходимо склонировать репозиторий выше к себе в **Git** и настроить пайплайн с этапом сборки образа и отправки его в любой **docker registry**. Для пайплайнов можно использовать **GitLab**, **Jenkins** или **GitHub Actions** — кому что нравится. Рекомендуем **GitLab**.

> *Таким образом, выбор систем CI/CD строго ограничет тремя конкретными вариантами; при этом выбор docker-registry - не ограничен. Исполнителем выбран вариант использования github/github actions/github registry.*

#### 2 Описываем приложение в Helm-чарт.

Описываем приложение в виде конфигов в **Helm**-чарте. По сути, там только два контейнера — с базой и приложением, так что ничего сложного в этом нет. Стоит хранить данные в БД с помощью **PVC** в **Kubernetes**.

> *В выбранном исполнителем варианте реализации (с учетом настойчивого требования заказчика по развертыванию СУБД - классического statefull-приложения - в обязательном порядке внутри кластера, с неприемлимостью со стороны заказчика использования внешнего по отношению к кластеру k8s сервиса СУБД) СУБД разоварачивается из чарта bitnami, тома хранения данных при развертывании - запрашиваются и предоставляются соответствующим провайдером (piraeus).*

#### 3 Описываем стадию деплоя в Helm.

Настраиваем деплой стадию пайплайна. Применяем **Helm**-чарт в наш кластер. Нужно сделать так, чтобы наше приложение разворачивалось после сборки в **Kubernetes** и было доступно по бесплатному домену или на **IP**-адресе с выбранным портом.

> *При использовании "бесплатного домена" в текущих реалиях развернутое приложение может не дождаться в работоспособном состоянии (из-за внешних факторов) проверки заказчиком, поэтому исполнителем - для учебного проекта - принято решение обеспечить доступ по IP-адресу (в Яндекс облаке) со стандартным портом http (80/tcp).*

Для деплоя должен использоваться свежесобранный образ. По возможности нужно реализовать сборку из тегов в **Git**, где тег репозитория в **Git** будет равен тегу собираемого образа.

Например:
![Пример](https://lms.skillfactory.ru/assets/courseware/v1/0bf548819cbf10a8cb8781e0019b6bd8/asset-v1:SkillFactory+DEVOPS-3.0+2021+type@asset+block/Sprint_2.2.png)

Чтобы создание такого тега запускало пайплайн на сборку образа c таким именем **hub.docker.com/skillfactory/testapp:2.0.3**.

> *Таким образом, заказчиком НЕ устанавливаются требования: (а) к размещению helm-чарта разворачиваемого приложения в специализированном реестре (и фактически допускается "локальная установка"); (б) к режиму развертывания helm-чарта (push/pull). Исполнителем принято решение использовать push-режим (после сборки образа контейнера и размещения его в реестре контейнеров следующее значимое действие запущенного pipline CI/CD - запустить "локально" установку чарта, которая "вытянет" только что сформированную сборку  (или не сформированную - в завимости от кэша слоев образа контейнера и фактических изменений кода приложения) и развернет приложение в прикладном k8s-кластере; возможность "локального" развертывания обеспечивается запуском self-hosted github actions runner-а в локальном периметре - согласно требованию заказчика на сервере srv (в обслуживающем кластере k8s))*

А на этом самый важный этап подходит к концу. А теперь сладкое под конец — в следующем спринте нам нужно настроить мониторинг и сборку логов приложения.

> *Если бы фактическое развертывание следовало предложенному плану - логи-мониторинг только в конце, уже после развертывания - служность развертывания и/или сопровождения решения увеличилась бы неоправданно значительно.*

В следующем спринте мы с вами создадим комфортные условия для работы нашей команды — добавим возможность смотреть логи и отслеживать метрики. Это точно всем пригодится!A

> *Фактически доступ к данным логгирования и мониторинга обеспечена в конце первого спринта (хранение данных обеспечивается на обслуживающем кластере - "сервере srv" - согласно требованиям заказчика). Доступ к данным обеспечен разработчикам/эксплуатирующим специалистам в веб-интерфейсах соответствующих решений через развернутую в первом спринте VPN (wireguard) до сервера-бастиона*

###   Модули к спринту

- [Система сборки](https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DEVOPS-3.0+2021/courseware/1818f1e4a2fa4e2aace76827bb5ed460/885de0c9e2ee44398fdab1bba148b848/1?activate_block_id=block-v1%3ASkillFactory%2BDEVOPS-3.0%2B2021%2Btype%40vertical%2Bblock%4069a57560e0e84e7c8b65cc0f4bf8971d)
- [Continuous Integration](https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DEVOPS-3.0+2021/courseware/1818f1e4a2fa4e2aace76827bb5ed460/b303682b402b41129d5f6658cab20010/1?activate_block_id=block-v1%3ASkillFactory%2BDEVOPS-3.0%2B2021%2Btype%40vertical%2Bblock%40b7660d2617c14700beff150dce6bff67)
- [Helm. CI/CD в Kubernetes](https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DEVOPS-3.0+2021/courseware/745596c246b742a79ea84c3e4ccf27b2/664d7bde52e843aca8b4270b3b88bb54/1?activate_block_id=block-v1%3ASkillFactory%2BDEVOPS-3.0%2B2021%2Btype%40vertical%2Bblock%4072f7b646a1ee45069400c30a51394048)


## Спринт 3

![Motivation](https://lms.skillfactory.ru/assets/courseware/v1/d0097bf4847418e64f5a78b73dd82d50/asset-v1:SkillFactory+DEVOPS-3.0+2021+type@asset+block/Sprint_3.1.png)

Мы с вами задеплоили наше приложение в созданную инфраструктуру.

Теперь — вишенка на торте — настройка мониторинга и логирования. Давайте декомпозируем.

#### 1 Настройка сборки логов.

Представьте, что вы разработчик, и вам нужно оперативно получать информацию с ошибками работы приложения.A

> *Также необходимо представить себя в роли эксплуатационного персонала и обеспечить доступ к логам и данным мониторинга как непосредственно прикладного кластера, так и обслуживающего кластера.*

Выберите инструмент, с помощью которого такой функционал можно предоставить. Нужно собирать логи работы пода приложения. Хранить это всё можно либо в самом кластере **Kubernetes**, либо на **srv**-сервере.

> *С учетом требований заказчика - обеспечивается хранение данных журналирования (и системных, и прикладных компонентов) в loki grafana (подсистема развернута в обслуживающем кластере). При этом на обслуживающем кластере журналы собираются штатно компонентом promtail развернутого локально для кластера решении prometheus (чарт от bitnami), а на прикладном кластере - развернутым "отдельно" promtail с push-передачей собираемых данных журналирования в сервис loki обслуживающего кластера.*

#### 2 Выбор метрик для мониторинга.

Так, теперь творческий этап. Допустим, наше приложение имеет для нас некоторую важность. Мы бы хотели знать, когда пользователь не может на него попасть — время отклика, сертификат, статус код и так далее. Выберите метрики и инструмент, с помощью которого будем отслеживать его состояние.

> *Для визуализации данных журналирования, мониторинга выбрано решение grafana (развернуто согласно требованиям заказчика в обслуживающем кластере (srv)). Анализ показателей (и реакция на них) обеспечивается непосредственно функционалом grafana - с учетом необходимого в дальнейшем в том числе при эксплуатации творчествеского подхода к обеспечению устойчивости развертываемого решения "графический" (grafana) режим должен обеспечить соответствующий уровень удобства заказчика (так что будет возможность оперативной организации мониторинга-реакции, например, бизнесс требований без необходимости заказчику пытаться организовать этот процесс, например, в alertmanager-е prometheus-а (с редактированием текстовых конфигурационных файлов, перезапуском сервиса)) - т.е. снижаем требование к квалификации непосредственного исполнителя задачи мониторинга (с учетом формулировки задачи об ограниченности ресурсов компании-заказчика).*

Также мы хотели бы знать, когда место на **srv**-сервере подходит к концу.

> *Соответствующие метрики - для обслуживающего кластера собираются (установленным стеком prometheus), мониторинг-реакция - исполнителем по проекту обеспечены (как и для прикладного кластера - в качестве примера возможности реализации).*

> **Важно!** Весь мониторинг должен находиться на **srv**-сервере, чтобы в случае падения кластера мы все равно могли узнать об этом.

> *Требование исполнителя сформулированно некорректно: согласно предложенной формулировке в том числе и сбор метрик должен производиться ДЛЯ ресурсов srv-сервера и на ресурсах srv-сервера (см. "весь мониторинг должен находится на srv"). Данное требование вступает в противоречие с иным требованием заказчика (см. выше "мы хотели бы знать, когда пользоваетель не может на него" (развертываемое прикладное приложение) "попасть...") - т.к. развертываемое прикладное приложение (сайт) развертывается согласно требованию же заказчика в прикладном k8s кластере - и  подлежит обязательному уточнению формулировки у заказчика в итоговых документах. Но, с учетом невозможности исполнителю получить доступ к заказчику для разъяснения данного вопроса (проект - учебный), исполнителем принято решение твочески требование изменить и обеспечить для данных мониторинга и журналирование _хранение_ в обслуживающем кластере (на сервере srv); при этом сбор метрик производится и на обслуживающем кластере (отдельный экземпляр1 prometheus), и на прикладном кластере (отдельный prometheus непосредственно на прикладном кластере) - со сбором(pull) данной информации экземпляром 2 prometheus обслуживающего кластера.  При этом разделение в обслуживающем кластере экземпляров хранения данных метрик (prometheus 1, 2), журналирования (loki 1, 2) позволяет выбирать свою процедуру хранения данных (например, для данных обслуживающего кластера - неделю, для данных прикладного кластера - месяц) и без изменений использовать сторонние дашборды grafana.*

#### 3 Настройка дашборда.

Ко всему прочему хотелось бы и наблюдать за метриками в разрезе времени. Для этого мы можем использовать **Grafana** и **Zabbix** — что больше понравилось.

> *Из предложенного строгого набора из двух позиций исполнителем выбран для использования вариант Grafana - для унификации работы с данными журналирования, мониторинга, "алертинга".*

#### 4 Алертинг.

А теперь добавим уведомления в наш любимый мессенджер, точнее в ваш любимый мессенджер. Обязательно протестируйте отправку уведомлений. Попробуйте «убить» приложение самостоятельно, и засеките время от инцидента до получения уведомления. Если время адекватное, то можно считать, что вы справились с этим проектом!

> *В grafana режим работы с telegram - штатный (исполнителем обеспечено получение уведомлений в приватный канал), шаблоны уведомлений - редактируемые (адаптация шаблона - исполнителем произведена); время реакции системы уведомления о событиях - штатное (т.е. "адекватное"), согласно настройкам пользователя (условно - в пределах 5 минут (изменяемая величина!) с учетом обработки со стороны системы уведомления возможной flip-flop ситуации).*

Самое время положить все возможные конфигурации в **Git**-репозиторий, если вы этого ещё не сделали.

> *Данным требованием ("...положить...в ... репозиторий..." - единственное число) заказчик уходит от предыдущего gitlab-ориентированного требования о размещении решения в группе репозиториев (см. комментарий выше). Исполнителем фактически размещены [репозиторий развертывания инфраструктуры](https://github.com/taa2021/c7-d0) и [репозиторий прикладного приложения](https://github.com/taa2021/sf-testapp) (с добавленым исполнителем helm-чартом развертывания данного приложения).*

###   Модули к спринту

- [Мониторинг в облачной среде. Визуализация, алертинг, трейсинг](https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DEVOPS-3.0+2021/courseware/e74c0a6b77f2436d9a308575e12d6e51/446ef955e4f74fd8a3404b2c1992fbc4/1?activate_block_id=block-v1%3ASkillFactory%2BDEVOPS-3.0%2B2021%2Btype%40vertical%2Bblock%4075a57dcf39c742aeaac8716b2980f01d)
- [Журналирование в Docker. Elasticsearch/Kibana/Logstash](https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DEVOPS-3.0+2021/courseware/e74c0a6b77f2436d9a308575e12d6e51/446ef955e4f74fd8a3404b2c1992fbc4/1?activate_block_id=block-v1%3ASkillFactory%2BDEVOPS-3.0%2B2021%2Btype%40vertical%2Bblock%4075a57dcf39c742aeaac8716b2980f01d)

## Раздел сдачи проекта

Для проверки выполненной работы отправьте ментору ссылку на группу репозиториев. А также ссылки на скриншоты дэшбордов мониторинга, реализации сборки логов, алертинга и сам адрес работающего приложения.
